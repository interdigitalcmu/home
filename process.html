<!DOCTYPE html><!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Sun May 02 2021 16:32:18 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="607dcfda5a1f814079f07093" data-wf-site="607dcf321ef9c11104c38e66">
<head>
  <meta charset="utf-8">
  <title>Process</title>
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/interdigital.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inter:100,200,300,regular,500,600,700,800,900","Space Grotesk:300,regular,500,600,700"]  }});</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tween.js/16.3.5/Tween.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.6.1/gsap.min.js" integrity="sha512-cdV6j5t5o24hkSciVrb8Ki6FveC2SgwGfLE31+ZQRHAeSRxYhAQskLkq3dLm8ZcWe1N3vBOEYmmbhzf7NTtFFQ==" crossorigin="anonymous"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inconsolata:400,700","Inter:100,200,300,regular,500,600,700,800,900","Space Grotesk:300,regular,500,600,700"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
</head>
<body class="body-2" data-index="1">
  <video id="mainTV" loop crossOrigin="anonymous" style="display:none" muted="muted">
    <source src="./Textures/SciFi.mp4" type='video/mp4'>
  </video>
      <video id="TomCruise" loop crossOrigin="anonymous" style="display:none" muted="muted">
    <source src="./Textures/DeepFake.mp4" type='video/mp4'>
  </video>
  <div data-collapse="medium" data-animation="default" data-duration="400" role="banner" class="navbar w-nav">
    <div class="container-4 w-container">
      <nav role="navigation" class="w-nav-menu">
        <a href="index.html" class="navbar-link w-nav-link" data-index="0">Home</a>
        <a href="opportunities.html" class="navbar-link w-nav-link" data-index="5">opportunities</a>
        <a href="#" class="navbar-link current-nav w-nav-link" data-index="1">process</a>
        <a href="team.html" class="navbar-link w-nav-link" data-index="9">team</a>
        <a href="https://interdigitalatcmu.medium.com/" target="_blank" class="navbar-link w-nav-link" data-index="0">blog</a>
      </nav>
      <div class="w-nav-button">
        <div class="w-icon-nav-menu"></div>
      </div>
    </div>
  </div>
  <div data-w-id="543a9394-3540-05ad-8a51-15890bdcee16" class="title-section process-title-section">
    <h1 class="title-card">PROCESS</h1>
  </div>
  <div class="tab-section">
    <div class="menu">
      <div data-w-id="ca6ee85c-9a0c-8902-d614-80859da56daa" class="menuitem-2 u-circle">
        <a href="#" class="menuitem-link-2 u-circle" data-index="2">pretotype</a>
      </div>
      <div data-w-id="ca6ee85c-9a0c-8902-d614-80859da56dad" class="menuitem-2 u-circle">
        <a href="#" class="menuitem-link-2 u-circle" data-index="3">primary research</a>
      </div>
      <div data-w-id="ca6ee85c-9a0c-8902-d614-80859da56db0" class="menuitem-2 u-circle">
        <a href="#" class="menuitem-link-2 u-circle" data-index="4">needfinding</a>
      </div>
    </div>
  </div>
  <div class="scroll-ind-section">
    <div class="scroll-ind-div">
      <div data-w-id="5e561926-f4cb-6e59-e8c9-902ea9535626" style="display:flex" class="text-block-2">Select tab<br><br><br>‍</div>
      <div data-w-id="8f3df683-6308-1b12-c1e5-65a745de23e6" style="display:none" class="text-block-2">Scroll<br><br><br>‍</div>
    </div>
  </div>
  <div class="content-section toc-section">
    <div class="div-block-7">
      <h3 class="paragraph-heading heading-space-long">Process</h3>
      <div class="w-layout-grid grid">
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">01</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text">Overview</div>
          </div>
        </div>
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">02</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text">Pretotype</div>
          </div>
        </div>
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">03</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text">Affinity Diagram</div>
          </div>
        </div>
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">04</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text toc-text-tl">Contextual Inquiry</div>
          </div>
        </div>
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">05</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text">Diary Study</div>
          </div>
        </div>
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">06</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text toc-text-tl">Conceptual Prototype</div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div id="goto-pretotype" data-w-id="fe383e66-a6db-63fe-4674-ec42df43d5a0" style="display:none" class="content-section">
    <div class="div-block-7">
      <h3 class="paragraph-heading heading-space-long">OvervieW</h3>
      <p class="paragraph-content">We found ourselves beginning our journey with an exceedingly ambiguous project description. Our goal was to employ user-centered design to speculate about novel user experiences in digital television that would satisfy user needs that are expected to emerge in the next 3 years. Our team used a variety of brainstorming activities, research methods, synthesis and design methodologies to narrow down our scope and get to the root of the problem we aimed to solve for. This section details brief summaries for each method and the most noteworthy insights and outcomes that have resulted.</p>
    </div>
    <div class="main-col-div">
      <h3 class="paragraph-heading heading-space-long">Pretotype</h3>
      <p class="paragraph-content">Since the first television program to air in 1928, the television format and the consumption of digital content itself has undergone major shifts and now comprises an essential fabric in modern society. Coming into a project with such a broad aim, we needed to find a way to explore the space of digital television without losing sight of the bigger picture and wasting unnecessary time and resources.</p>
    </div>
    <div class="main-col-div">
      <div class="paragraph-line"></div>
      <p class="paragraph-content">We had recently had a conversation with our client discussing key assumptions around television that could be worth exploring. This got us thinking… Can we transport participants into a future state where these assumptions are reversed? Examples of such assumptions were the use of certain controls, the two dimensional format of TV and the fact that its static. We also wanted to explore factors such as immersion and social behaviors within this state.</p>
      <div class="columns w-row">
        <div class="column-7 w-col w-col-6"><img src="images/pretotype1.JPG" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 420px, 42vw" srcset="images/pretotype1-p-500.jpeg 500w, images/pretotype1.JPG 1093w" alt="" class="image-6"></div>
        <div class="column-8 w-col w-col-6"><img src="images/pretotype2.JPG" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 420px, 42vw" srcset="images/pretotype2-p-500.jpeg 500w, images/pretotype2.JPG 1093w" alt="" class="image-7"></div>
      </div>
      <p class="paragraph-content">We introduce our Pretotype, the Context Aware Moving Television, and the Visuo-auditory Immersion System. These were scenarios where the television has been freed from the bounds of a static two dimensional artifact and where the television is capable of providing enhanced 3D projection and surround sound audio.</p>
    </div>
    <div class="main-col-div">
      <h3 class="paragraph-heading heading-space-short">affinity diagramming</h3>
      <p class="paragraph-content">Through affinity diagramming we’ve condensed the qualitative data from the sessions and interviews. What became apparent to us is that television has already broken the bounds of its traditional box within the living room wall, not just ergonomically, but also conceptually. While the reason people watch TV has not changed, the ability to have it within the palm of one’s hand has brought with it, a need for robustness and adaptability that users have come to expect.</p><img src="images/Pretotype-Synthesis.jpg" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 900px, 91vw" srcset="images/Pretotype-Synthesis-p-500.jpeg 500w, images/Pretotype-Synthesis-p-1080.jpeg 1080w, images/Pretotype-Synthesis.jpg 1530w" alt="" class="image-3">
      <div class="paragraph-line"></div>
      <div class="insight-div">
        <div class="columns-3 w-row">
          <div class="column-10 w-col w-col-3">
            <div class="text-block-5">01</div>
          </div>
          <div class="column-9 w-col w-col-9">
            <div class="text-block-6 p-heading6">Adaptation</div>
          </div>
        </div>
        <p class="paragraph-content">Immersion is not a hook that can guarantee long-term values for users. The constraints that are necessitated by enhanced immersion was a big point of contention in an era where television is literally in the palm of one’s hand. People are not willing to go out of their way for alternate experiences that are inherently sedentary. The takeaway is that alternate experiences must be adapted to the existing lifestyle of the user.</p>
      </div>
      <div class="insight-div">
        <div class="columns-4 w-row">
          <div class="column-10 w-col w-col-3">
            <div class="text-block-5">02</div>
          </div>
          <div class="column-9 w-col w-col-9">
            <div class="text-block-6 p-heading6">Collective Experience</div>
          </div>
        </div>
        <p class="paragraph-content">In spite of the downsides of enhanced immersion that was brought up in the second scenario, it was revealed that people were willing to make strides to create alternate TV experiences if it was a part of a collective experience.This along with the general sentiment of TV’s role within social settings and as a social artifact drives home the point that the collective experience is majorly important when watching with other people.</p>
      </div>
      <div class="insight-div">
        <div class="columns-5 w-row">
          <div class="column-10 w-col w-col-3">
            <div class="text-block-5">03</div>
          </div>
          <div class="column-9 w-col w-col-9">
            <div class="text-block-6 p-heading6">Attention Switching</div>
          </div>
        </div>
        <p class="paragraph-content">People do not necessarily watch TV to watch TV. In many cases TV was simply the means to an end, and is most ubiquitously used in conjunction with tasks that do not require full attention, which is where it triumphs over other forms of digital entertainment. Why do people choose TV? Because they can switch their attention to and from it very easily.</p>
      </div>
    </div>
  </div>
  <div id="goto-contextualinquiry" data-w-id="24d4b8d2-b332-afc5-4661-a81358aeb748" style="display:none" class="content-section">
    <div class="main-col-div">
      <h3 class="paragraph-heading heading-space-short">contextual inquiry</h3>
      <p class="paragraph-content">It was at this point that we realized that there is more to the shift within the digital television landscape than just the delivery mechanism, but to the content itself. We also needed to understand what TV and digital content means to users in a real-life context.</p><img src="images/pexels-christina-morillo-1181712.jpg" loading="lazy" sizes="(max-width: 479px) 100vw, (max-width: 767px) 71vw, (max-width: 991px) 80vw, 87vw" srcset="images/pexels-christina-morillo-1181712-p-1080.jpeg 1080w, images/pexels-christina-morillo-1181712-p-1600.jpeg 1600w, images/pexels-christina-morillo-1181712-p-2000.jpeg 2000w, images/pexels-christina-morillo-1181712-p-2600.jpeg 2600w, images/pexels-christina-morillo-1181712-p-3200.jpeg 3200w, images/pexels-christina-morillo-1181712.jpg 5760w" alt="" class="image-3">
      <p class="paragraph-content">With our new focus on digital content and its role in real-life routines, we began our deep exploration into how TV blends itself into people’s daily lives and how different content fit into varying contexts. We did so by conducting contextual inquiries and diary studies with a pool of participants with diverse demographic backgrounds. We then conducted 5-Whys sessions to get into the root of the problem. What we found was that many of our pretotype insights were reliably validated, and that there are surprising needs that are being specifically met with the use of digital content, especially within a content capturing and sharing perspective.</p>
    </div>
    <div class="main-col-div">
      <div class="paragraph-line"></div>
      <h3 class="paragraph-heading heading-space-short">diary study</h3>
      <p class="paragraph-content">While conducting the contextual inquiries, we used the same participant pool to tackle the questions of &quot;what are users’ current digital content consumption habits and experiences?&quot; from a different angle by conducting a diary study in parallel. We had our users log in their daily activities over a 7-day period. The activities they reported including their interactions with TV, technologies, as well as activities outside of the digital space.</p><img src="images/pexels-pixabay-261735.jpg" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 900px, 91vw" srcset="images/pexels-pixabay-261735-p-1080.jpeg 1080w, images/pexels-pixabay-261735-p-1600.jpeg 1600w, images/pexels-pixabay-261735-p-2000.jpeg 2000w, images/pexels-pixabay-261735-p-2600.jpeg 2600w, images/pexels-pixabay-261735-p-3200.jpeg 3200w, images/pexels-pixabay-261735.jpg 4000w" alt="" class="image-3">
    </div>
    <div class="main-col-div">
      <div class="paragraph-line"></div>
      <h3 class="paragraph-heading heading-space-short">experience mapping</h3><img src="images/IMG-0093.png" loading="lazy" sizes="(max-width: 991px) 100vw, 1499.984375px" srcset="images/IMG-0093-p-500.png 500w, images/IMG-0093-p-800.png 800w, images/IMG-0093-p-1080.png 1080w, images/IMG-0093-p-1600.png 1600w, images/IMG-0093-p-2000.png 2000w, images/IMG-0093.png 2269w" alt="" class="image-3">
      <p class="paragraph-content iidp">We also distilled our diary study via experience mapping in order to create an amalgamated environmental persona consisting of routines, moods, and context that will be used as a foundation for future design iterations.</p>
      <div class="paragraph-line"></div>
      <div class="insight-img-div iid2">
        <div class="insight-img-div---sub">
          <div class="columns-6 w-row">
            <div class="column-10 w-col w-col-3">
              <div class="text-block-5">01</div>
            </div>
            <div class="column-9 w-col w-col-9">
              <div class="text-block-6">Digital Content Permeates our Lfie</div>
            </div>
          </div>
          <p class="paragraph-content iidp">People consume digital content almost all the time as a secondary activity and crave the convenience of being able to access content anytime and anywhere when doing some mundane tasks. People multitask all the time, and so there is a need for the TV content to adapt based on users&#x27; context.</p>
        </div>
        <div class="insight-img-div---sub"><img src="images/Escapism2.jpg" loading="lazy" sizes="(max-width: 479px) 400px, (max-width: 767px) 500px, (max-width: 991px) 600px, 700px" srcset="images/Escapism2-p-800.jpeg 800w, images/Escapism2-p-1080.jpeg 1080w, images/Escapism2.jpg 1152w" alt="" class="image-9"></div>
      </div>
      <div class="insight-img-div">
        <div class="insight-img-div---sub"><img src="images/Social-viewing.jpg" loading="lazy" sizes="(max-width: 479px) 400px, (max-width: 767px) 500px, (max-width: 991px) 600px, 700px" srcset="images/Social-viewing-p-500.jpeg 500w, images/Social-viewing-p-800.jpeg 800w, images/Social-viewing-p-1080.jpeg 1080w, images/Social-viewing-p-1600.jpeg 1600w, images/Social-viewing-p-2000.jpeg 2000w, images/Social-viewing-p-2600.jpeg 2600w, images/Social-viewing.jpg 3200w" alt="" class="image-9"></div>
        <div class="insight-img-div---sub">
          <div class="columns-7 w-row">
            <div class="column-10 w-col w-col-3">
              <div class="text-block-5">02</div>
            </div>
            <div class="column-9 w-col w-col-9">
              <div class="text-block-6">Company Over Content</div>
            </div>
          </div>
          <p class="paragraph-content iidp">People also crave connection. They want to create a collective TV viewing experience so they can build connections with one another. When viewing in groups, users care more about socializing and talking about the show over picking the content they would want to watch by themselves. When in social context, there is a need for the TV content to adapt the needs of multiple parties.</p>
        </div>
      </div>
      <div class="insight-img-div iid2">
        <div class="insight-img-div---sub">
          <div class="columns-8 w-row">
            <div class="column-10 w-col w-col-3">
              <div class="text-block-5">03</div>
            </div>
            <div class="column-9 w-col w-col-9">
              <div class="text-block-6">TV as an Emotional Tool</div>
            </div>
          </div>
          <p class="paragraph-content iidp">People use the TV as an emotional tool to help them cope with stress and frustration. Many users pick what to play based on the mood feelings they are in. Understanding these experiences raised the question for us, Can TV and digital content be used to regulate people&#x27;s emotions?</p>
        </div>
        <div class="insight-img-div---sub"><img src="images/pexels-anna-shvets-4226221.jpg" loading="lazy" sizes="(max-width: 479px) 400px, (max-width: 767px) 500px, (max-width: 991px) 600px, 700px" srcset="images/pexels-anna-shvets-4226221-p-500.jpeg 500w, images/pexels-anna-shvets-4226221-p-800.jpeg 800w, images/pexels-anna-shvets-4226221-p-1080.jpeg 1080w, images/pexels-anna-shvets-4226221-p-2000.jpeg 2000w, images/pexels-anna-shvets-4226221-p-2600.jpeg 2600w, images/pexels-anna-shvets-4226221.jpg 3103w" alt="" class="image-9"></div>
      </div>
      <div class="insight-img-div">
        <div class="insight-img-div---sub"><img src="images/pexels-anna-nekrashevich-7550902.jpg" loading="lazy" sizes="(max-width: 479px) 400px, (max-width: 767px) 500px, (max-width: 991px) 600px, 700px" srcset="images/pexels-anna-nekrashevich-7550902-p-500.jpeg 500w, images/pexels-anna-nekrashevich-7550902-p-800.jpeg 800w, images/pexels-anna-nekrashevich-7550902-p-1080.jpeg 1080w, images/pexels-anna-nekrashevich-7550902-p-1600.jpeg 1600w, images/pexels-anna-nekrashevich-7550902-p-2000.jpeg 2000w, images/pexels-anna-nekrashevich-7550902-p-2600.jpeg 2600w, images/pexels-anna-nekrashevich-7550902-p-3200.jpeg 3200w, images/pexels-anna-nekrashevich-7550902.jpg 3508w" alt="" class="image-9"></div>
        <div class="insight-img-div---sub">
          <div class="columns-9 w-row">
            <div class="column-10 w-col w-col-3">
              <div class="text-block-5">04</div>
            </div>
            <div class="column-9 w-col w-col-9">
              <div class="text-block-6">Molding the Content</div>
            </div>
          </div>
          <p class="paragraph-content iidp">People want to “mold” the content they capture to present their stories for certain audiences. Despite frequently capturing moments of his or her personal life, users were very selective about what to post on social media because it would be open for all to see it. As much as they would like to share pictures on Instagram, they abstain to avoid certain audiences.</p>
        </div>
      </div>
      <div class="insight-img-div iid2">
        <div class="insight-img-div---sub">
          <div class="columns-10 w-row">
            <div class="column-10 w-col w-col-3">
              <div class="text-block-5">05</div>
            </div>
            <div class="column-9 w-col w-col-9">
              <div class="text-block-6">Re-experiencing the Past</div>
            </div>
          </div>
          <p class="paragraph-content iidp">People want to use content capturing to escape from current reality by reflecting or re-experiencing their past. Some users consciously posted content aiming for mass responses, others would much rather keep captured moments to themselves or shared it with a select group of people. We see that content creation becomes a more personal experience.</p>
        </div>
        <div class="insight-img-div---sub"><img src="images/pexels-andre-moura-3151392.jpg" loading="lazy" sizes="(max-width: 479px) 400px, (max-width: 767px) 500px, (max-width: 991px) 600px, 700px" srcset="images/pexels-andre-moura-3151392-p-500.jpeg 500w, images/pexels-andre-moura-3151392-p-800.jpeg 800w, images/pexels-andre-moura-3151392-p-1080.jpeg 1080w, images/pexels-andre-moura-3151392-p-1600.jpeg 1600w, images/pexels-andre-moura-3151392-p-2000.jpeg 2000w, images/pexels-andre-moura-3151392.jpg 2448w" alt="" class="image-9"></div>
      </div>
    </div>
  </div>
  <div id="goto-conceptualprototype" data-w-id="516383e6-03dc-d694-125f-1076a6d7f5c4" style="display:none" class="content-section">
    <div class="main-col-div">
      <h3 class="paragraph-heading heading-space-short">conceptual prototype</h3>
      <p class="paragraph-content">Beyond understanding the ebb and flow of digital content in the current state, we also have to envision what it would be like in the future. If there is one thing we know about the incorporation of technology when transitioning into the future, it&#x27;s that it is not enough for it to push the boundaries of what’s possible, but to be the solution that people are ready to embrace. Inspired by the work from our faculty advisors, we explored the future of TV and synthetic content through a future-thinking game, where participants were asked to collaboratively define a future scenario and come up with possible items that would exist from that future.</p><img src="images/The-TV-Thing-From-the-Future.jpg" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 900px, 91vw" srcset="images/The-TV-Thing-From-the-Future-p-800.jpeg 800w, images/The-TV-Thing-From-the-Future-p-1080.jpeg 1080w, images/The-TV-Thing-From-the-Future.jpg 1530w" alt="" class="image-3">
      <p class="paragraph-content">Between these group sessions, we offered participants the opportunity to vote for the best idea(s), judged based on how well it fits the prompt and how likely it will occur in the future scenario. We also facilitated additional post-game discussions to discuss why participants selected certain ideas, to glean their views and thoughts of the future they had defined.</p>
      <div class="paragraph-line"></div>
      <div class="insight-div">
        <div class="columns-11 w-row">
          <div class="column-10 w-col w-col-3">
            <div class="text-block-5">01</div>
          </div>
          <div class="column-9 w-col w-col-9">
            <div class="text-block-6 p-heading6">Indulging in Emotions</div>
          </div>
        </div>
        <p class="paragraph-content">People use content to indulge in their emotions. Across all our game sessions, participants were eager to immerse themselves in virtual environments based on the mood that they were in. We realized that people let their emotions dictate the content they consume and create, and they anticipate that content would further regulate their mood in the future.</p>
      </div>
      <div class="insight-div">
        <div class="columns-12 w-row">
          <div class="column-10 w-col w-col-3">
            <div class="text-block-5">02</div>
          </div>
          <div class="column-9 w-col w-col-9">
            <div class="text-block-6 p-heading6">Stepping into Another&#x27;s Shoes</div>
          </div>
        </div>
        <p class="paragraph-content">People want to experience content from a different perspective. Participants envisioned themselves reliving stories from a first person perspective, or be put into a simulation environment to better learn at school. Whether it is to empathize with fictional characters or to enhance their learning, people have expressed a desire to step into one’s shoes and experience content differently.</p>
      </div>
      <div class="insight-div">
        <div class="columns-13 w-row">
          <div class="column-10 w-col w-col-3">
            <div class="text-block-5">03</div>
          </div>
          <div class="column-9 w-col w-col-9">
            <div class="text-block-6 p-heading6">Anticipations by Intellegent Systems</div>
          </div>
        </div>
        <p class="paragraph-content">People envisioned intelligent systems that could anticipate their needs. Especially in relation to content consumption, there remains this friction between what the user wants and what TVs can do automatically in response to that. People are hopeful for a more intelligent system that can accurately infer their needs, and adapt the content accordingly.</p>
      </div>
    </div>
  </div>
  <div class="page-background content"></div>
  <div class="page-background">
    <div style="opacity:0" class="background-color"></div>
    <div class="_3d-scene"></div>
  </div>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=607dcf321ef9c11104c38e66" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
  <script type="module">
    // Find the latest version by visiting https://unpkg.com/three.          
    import * as THREE from 'https://unpkg.com/three@0.127.0/build/three.module.js';
    import { GUI } from 'https://unpkg.com/three@0.127.0/examples/jsm/libs/dat.gui.module.js';
    import { GLTFLoader } from 'https://unpkg.com/three@0.127.0/examples/jsm/loaders/GLTFLoader.js';
    import { EffectComposer } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/EffectComposer.js';
    import { RenderPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/RenderPass.js';
    import { UnrealBloomPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/UnrealBloomPass.js';
    import { SSAOPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/SSAOPass.js';
    import Stats from 'https://unpkg.com/three@0.127.0/examples/jsm/libs/stats.module';

    const loader = new GLTFLoader();

    const scene = new THREE.Scene();
    loader.load('./Models/WebsiteScene.glb', function(gltf) {
        console.log(gltf.scene);
        scene.add(gltf.scene);
        configGLTBScene();
        init();
        animate();
        gsap.to(".content", {css: {backgroundColor: "rgba(0,0,0,0.4)"}, delay: 2})
    })

    // let stats = new Stats();

    const fov = 80;
    const aspect = 1.8;  // the canvas default
    const near = 0.1;
    const far = 1000;
    const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
    let cameraPosition = new THREE.Vector3(0, 2, 10);
    let cameraLookAtPosition = new THREE.Vector3(0, 0, 0); // TODO: Lerp between objects via tweening
    let lookAtObject = new THREE.Object3D();

    camera.position.set(cameraPosition.x, cameraPosition.y, cameraPosition.z);
    var renderer = new THREE.WebGLRenderer({
        antialias: true,
        alpha: true
    });

    var canvas = renderer.domElement;
    document.body.appendChild(canvas);

    var plane = new THREE.Plane(new THREE.Vector3(0, 0, 1), -10);
    var raycaster = new THREE.Raycaster();
    var mouse = new THREE.Vector2();
    var look = new THREE.Vector2();
    var pointOfIntersection = new THREE.Vector3();

    document.addEventListener("mousemove", onMouseMove, false);

    const PPParams = {
        exposure: 1,
        bloomStrength:  0.7,
        bloomThreshold: 0,
        bloomRadius: 0
    };

    function onMouseMove(event){
        mouse.x = ( event.clientX / window.innerWidth ) * 2 - 1;
        mouse.y = - ( event.clientY / window.innerHeight ) * 2 + 1;
    }

    let texturePaths = ['Textures/About/Phipson.jpg', "Textures/About/Lee_Aaron.jpg", "Textures/About/Mohan_Divya.JPG", "Textures/About/Chen_Maggie.JPG", "Textures/About/Suazo_Gabriela.jpg"]
    function configGLTBScene() {
        // Set floor color
        scene.getObjectByName('Floor', true).material.color.setHex(0xF1F0E4);

        // Add the about me
        let billboardText = new THREE.TextureLoader().load("Textures/TeamPhoto.png"); 
        billboardText.wrapS = THREE.RepeatWrapping;
        billboardText.wrapT = THREE.RepeatWrapping;
        billboardText.repeat.set(-1, 1);
        scene.getObjectByName('About_Billboard', true).material = new THREE.MeshLambertMaterial({map: billboardText});
        scene.getObjectByName('About_Billboard', true).material.side = THREE.DoubleSide;

        // Add TV Video Texture
        video = document.getElementById( 'mainTV' );
        video.play();

        texture = new THREE.VideoTexture( video );
        texture.minFilter = THREE.NearestFilter;

        const parameters = { map: texture, emissiveIntensity: 3.0 };
        scene.getObjectByName("FutureTV", true).material = new THREE.MeshBasicMaterial( { map:  texture } );
        scene.getObjectByName("SonyTVScreen", true).material = new THREE.MeshLambertMaterial( { map:  texture } );

        // Add iPhone Deep Fake Texture
        deepFake = document.getElementById('TomCruise');
        deepFake.play();

        df_texture = new THREE.VideoTexture(deepFake);
        df_texture.minFilter = THREE.NearestFilter;
        let df_material = new THREE.MeshLambertMaterial( { map:  df_texture } );
        scene.getObjectByName(`iphone_12015_1`, true).material = df_material
        scene.getObjectByName(`iphone_12015_4`, true).material = df_material
        scene.getObjectByName(`iphone_12015_5`, true).material = df_material
        
        // Add card textures
        for (let i = 0; i < 7; i++) {
            let texture = new THREE.TextureLoader().load(`Textures/Cards/Card_${i+1}.png`);
            texture.wrapS = THREE.RepeatWrapping;
            texture.wrapT = THREE.RepeatWrapping;
            texture.repeat.set(-1, 1);
            scene.getObjectByName(`Card_${i+1}`, true).material = new THREE.MeshLambertMaterial( { map:  texture, emissiveIntensity: 0.1 } );
        }

        // Set couch material color
        for (let i = 0; i < 12; i++) {
            scene.getObjectByName(`Couch_${i+1}`, true).material.color.setHex(0x6A2E35);
        }

        // Set coffee table material color
        scene.getObjectByName('CoffeeTableSurface', true).material = new THREE.MeshLambertMaterial({color: 0xDDA77B});
        scene.getObjectByName('CoffeeTableLegs', true).material = new THREE.MeshLambertMaterial({color: 0x283845});
        scene.getObjectByName('CoffeeTableSupports', true).material = new THREE.MeshLambertMaterial({color: 0x283845});

        // Projector
        scene.getObjectByName('Plane002', true).material = new THREE.MeshLambertMaterial({color: 0xDAD6D6});

        // TV Stand Cabinets
        let cabinetMat = new THREE.MeshLambertMaterial({color: 0xB6C2D9});
        let surfaceMat = new THREE.MeshLambertMaterial({color: 0x171D1C})
        scene.getObjectByName('236obj05', true).material = surfaceMat;
        scene.getObjectByName('236obj04', true).material = cabinetMat;
        scene.getObjectByName('236obj02', true).material = cabinetMat;
        scene.getObjectByName('Mesh457', true).material = cabinetMat;

        scene.getObjectByName(`Opportunity_DigitalDouble`, true).material = new THREE.MeshLambertMaterial({color: 0x08d9d6, opacity: 0.1, transparent: true});
    }

    let video, texture, deepFake, df_texture, material, mesh, box, composer, effectFXAA;
    function initDebugGUI() {
      const gui = new GUI();

      gui.add( PPParams, 'exposure', 0.1, 2 ).onChange( function ( value ) {

          renderer.toneMappingExposure = Math.pow( value, 4.0 );

      } );

      gui.add( PPParams, 'bloomThreshold', 0.0, 1.0 ).onChange( function ( value ) {

          bloomPass.threshold = Number( value );

      } );

      gui.add( PPParams, 'bloomStrength', 0.0, 3.0 ).onChange( function ( value ) {

          bloomPass.strength = Number( value );

      } );

      gui.add( PPParams, 'bloomRadius', 0.0, 1.0 ).step( 0.01 ).onChange( function ( value ) {

          bloomPass.radius = Number( value );

      } );

      gui.open();
    }


    function init() {
        lookAtObject.position.x = 0; lookAtObject.position.y = 0; lookAtObject.position.z = 0; 
        scene.add(lookAtObject)

        const color = 0x0;
        const density = 0.1;
        scene.fog = new THREE.FogExp2(color, density);

        // POST PROCESSING
        const renderScene = new RenderPass( scene, camera );
        const bloomPass = new UnrealBloomPass( new THREE.Vector2( window.innerWidth, window.innerHeight ), 1.5, 0.4, .85 );
        bloomPass.threshold = PPParams.bloomThreshold;
        bloomPass.strength = PPParams.bloomStrength;
        bloomPass.radius = PPParams.bloomRadius;
        renderer.setSize(window.innerWidth, window.innerHeight);

        const ssaoPass = new SSAOPass( scene, camera, window.innerWidth, window.innerHeight );
        ssaoPass.kernelRadius = 16;
        renderer.setClearColor( color, 1 );

        composer = new EffectComposer( renderer );
        composer.addPass( renderScene );
        composer.addPass( bloomPass );
        // composer.addPass(ssaoPass);

        // document.body.appendChild(stats.dom);
        // document.body.addEventListener('keydown', keyPressed);
        document.body.addEventListener('resize', onWindowResize)

        setupTween();
        SetCameraSpotlight($('body').data("index"));
        // initDebugGUI();
    }

    var easeAmount = 8;
    var sensitivity = 0.0005;
    function update() {
        if (spotLightHelper) spotLightHelper.update();
        lookAtObject.position.x = cameraLookAtPosition.x;
        lookAtObject.position.y = cameraLookAtPosition.y;
        lookAtObject.position.z = cameraLookAtPosition.z;

        look.x += (mouse.x-look.x)/easeAmount;
        look.y += (mouse.y-look.y)/easeAmount;
        
        camera.position.x = cameraPosition.x + look.x * window.innerWidth * sensitivity;
        camera.position.y = cameraPosition.y + look.y * window.innerHeight * sensitivity;
        camera.position.z = cameraPosition.z;

        camera.lookAt(lookAtObject.position);
        // stats.update();
        TWEEN.update();
    }

    function animate() 
    {
        requestAnimationFrame( animate );
        composer.render();
        // render();		
        update();
    }

    function render() 
    {	
        if ( video.readyState === video.HAVE_ENOUGH_DATA ) 
        {
            if ( texture ) 
                texture.needsUpdate = true;
        }

        if (resize(renderer)) {
            camera.aspect = canvas.clientWidth / canvas.clientHeight;
            camera.updateProjectionMatrix();
        }

        renderer.render( scene, camera );
    }

    function resize(renderer) {
        const canvas = renderer.domElement;
        const width = canvas.clientWidth;
        const height = canvas.clientHeight;
        const needResize = canvas.width !== width || canvas.height !== height;
        if (needResize) {
            renderer.setSize(width, height, false);
        }
        return needResize;
    }

    function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize( window.innerWidth, window.innerHeight );
    }

    // function keyPressed(e) {
    //     switch(e.key) {
    //         case 'ArrowLeft':
    //             cameraTweenIndex = cameraTweenIndex - 1 < 0 ? cameraSpotlightConfig.length - 1 : cameraTweenIndex - 1;
    //             updateCameraTransform();
    //             updateSpotlight();
    //             break;
    //         case 'ArrowRight':
    //             cameraTweenIndex = cameraTweenIndex + 1 >= cameraSpotlightConfig.length ? 0 : cameraTweenIndex + 1;
    //             updateCameraTransform();
    //             updateSpotlight();
    //             break;
    //     }
    //     e.preventDefault();
    // }

    function SetCameraSpotlight(newTweenIndex) {
        cameraTweenIndex = newTweenIndex;
        updateCameraTransform();
        updateSpotlight();
    }

    let cameraSpotlightConfig = [
        {
            focusObj: "FutureTV",
            positionName: "Position_Main",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "CoffeeTableSurface",
            positionName: "Position_Research",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "Projector",
            positionName: "Position_Research_Pretotype",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 1.5,
        },
        {
            focusObj: "SonyTV",
            positionName: "Position_Research_Current",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "Card_7",
            positionName: "Position_Research_Future",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 1.5,
        },
        {
            focusObj: "Opportunity_DigitalDouble",
            positionName: "Position_Opportunity",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "Opportunity_DeepFake",
            positionName: "Position_Opportunity_ContentCreation",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "Focus_DigitalDouble",
            positionName: "Position_Opportunity_DigitalDouble",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "Focus_VintageTV",
            positionName: "Position_Opportunity_ContextAware",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "About_Billboard",
            positionName: "Position_About",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
    ]

    let default_color = 0xF1F0E4;
    let cameraTweenIndex = 0;
    let spotlight, spotLightHelper;
    function setupTween() {
        TWEEN.removeAll();

        spotlight = createSpotlight(default_color);
        scene.add(spotlight);

        // spotLightHelper = new THREE.SpotLightHelper( spotlight );
        // scene.add( spotLightHelper );

        cameraSpotlightConfig.forEach((config, i) => {
            // console.log(config);
            let obj = scene.getObjectByName(config.focusObj, true);
            const camPos = scene.getObjectByName(config.positionName, true).position;
            config.lookAt = new THREE.Vector3(obj.position.x, obj.position.y, obj.position.z);
            config.cameraPos = new THREE.Vector3(camPos.x, camPos.y, camPos.z);
        })
    }

    function updateCameraTransform() {
        const temp = cameraSpotlightConfig[cameraTweenIndex];

        let tempPos = cameraPosition;
        let newCamPos = temp.cameraPos;
        let tempLookAt = lookAtObject.position;
        let newLookAt = temp.lookAt;

        // console.log(newCamPos);

        new TWEEN.Tween(tempPos)
        .to(newCamPos, 2000)
        .easing (TWEEN.Easing.Cubic.InOut)
        .onUpdate(function() { cameraPosition = tempPos; })
        .start();

        new TWEEN.Tween(tempLookAt)
        .to(newLookAt, 2000)
        .easing (TWEEN.Easing.Cubic.InOut)
        .onUpdate(function() { cameraLookAtPosition = tempLookAt; })
        .start();
    }

    function createSpotlight(color) {
        const newObj = new THREE.SpotLight(color, 2);

        newObj.castShadow = true;
        newObj.angle = 0.5;
        newObj.penumbra = 0.5;
        newObj.decay = 2;
        newObj.distance = 20;
        newObj.target = lookAtObject;

        return newObj;
    }

    function updateSpotlight() {
        const temp = cameraSpotlightConfig[cameraTweenIndex];
        console.log(temp);

        let tempPosition = spotlight.target.position;
        let tempIntensity = spotlight.intensity;

        new TWEEN.Tween(spotlight.position)
        .to({x: temp.cameraPos.x, y: 10, z: temp.cameraPos.z}, 1000)
        .easing(TWEEN.Easing.Cubic.InOut)
        .start();

        spotlight.color.setHex(temp.lightColor);
        spotlight.intensity = temp.lightIntensity;
    }

    window.addEventListener( 'resize', function () {
			  camera.aspect = window.innerWidth / window.innerHeight;
			  camera.updateProjectionMatrix();
			  renderer.setSize( window.innerWidth, window.innerHeight );
			}, false );

    $('.navbar-link').on('click', function(e) {
      e.preventDefault();
      SetCameraSpotlight($(this).data("index"));
      if (!this.href.includes("#")) {
        gsap.to(".content", {css: {backgroundColor: "rgba(0,0,0,1)"}, duration: 0.5})
        setTimeout(() => {
          window.location = this.href
        }, 1000);
      }
    })

    $('.menuitem-link-2').on('click', function(e) {
      e.preventDefault();
      SetCameraSpotlight($(this).data("index"));
    })

    $('.home-menu-title').hover(function(e) {
      gsap.to($(this), {css: {color: '#6783E6'}, duration: 0.25});
    }, function(e) {
      if ($(this).hasClass('current-nav')) {
        gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
      }
      else {
        gsap.to($(this), {css: {color: '#f1f0e4'}, duration: 0.25});
      }
    })

    $('.navbar-link').hover(function(e) {
      gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
    }, function(e) {
      if ($(this).hasClass('current-nav')) {
        gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
      }
      else {
        gsap.to($(this), {css: {color: '#f1f0e4'}, duration: 0.25});
      }
    })
  </script>
</body>
</html>