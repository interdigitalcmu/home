<!DOCTYPE html><!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Tue Aug 10 2021 20:07:52 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="607dcfda5a1f814079f07093" data-wf-site="607dcf321ef9c11104c38e66">
<head>
  <meta charset="utf-8">
  <title>Research | The Future of Digital Television</title>
  <meta content="Research | The Future of Digital Television" property="og:title">
  <meta content="Research | The Future of Digital Television" property="twitter:title">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/interdigital.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inter:100,200,300,regular,500,600,700,800,900","Space Grotesk:300,regular,500,600,700"]  }});</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tween.js/16.3.5/Tween.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.6.1/gsap.min.js" integrity="sha512-cdV6j5t5o24hkSciVrb8Ki6FveC2SgwGfLE31+ZQRHAeSRxYhAQskLkq3dLm8ZcWe1N3vBOEYmmbhzf7NTtFFQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.7.1/ScrollTrigger.min.js" integrity="sha512-DlTk2PLUinhBupE89kHOJTt11QqbRMQVlbb26XVDvp4D1kt0fRvQJslvZnTelRJHq6yK0tIPCR7cul8+9Blz0g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.7.1/ScrollToPlugin.min.js" integrity="sha512-1OG9UO4krPizjtz/c9iDbjCqtXznBYdJeD4ccPaYfJHzC6F1qoQ3P1bgQ3J8lgCoK5qGVCqsY4+/RKjLDzITVQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inconsolata:400,700","Inter:100,200,300,regular,500,600,700,800,900","Space Grotesk:300,regular,500,600,700"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
</head>
<body class="body-2" data-index="2">
  <video id="mainTV" autoplay muted loop crossOrigin="anonymous" style="display:none">
    <source src="./Textures/SciFi.mp4" type='video/mp4'>
  </video>
  <div data-w-id="543a9394-3540-05ad-8a51-15890bdcee16" class="title-section process-title-section wf-section">
    <h1 class="title-card">process<br><strong class="bold-text-11">Research</strong></h1>
  </div>
  <div class="scroll-ind-section wf-section">
    <div class="scroll-ind-div">
      <div data-w-id="74b91997-e09f-48d4-bb56-94494349b32b" data-animation-type="lottie" data-src="documents/lf30_editor_rdgpmu2e.json" data-loop="1" data-direction="1" data-autoplay="1" data-is-ix2-target="0" data-renderer="svg" data-default-duration="3" data-duration="0" class="scroll_lottie"></div>
    </div>
  </div>
  <div id="goto-pretotype" class="content-section wf-section">
    <div id="navigation-anchor" class="side-nav-div">
      <div class="div-block-23">
        <a href="#overview" class="sidenav-link">OVERVIEW</a>
        <a href="#methods" class="sidenav-link">METHODS</a>
        <a href="#current-state" class="sidenav-link">CURRENT STATE</a>
        <a href="#future-state" class="sidenav-link">FUTURE STATE</a>
        <a href="#insights" class="sidenav-link">INSIGHTS</a>
        <a href="#evidence" class="sidenav-link">EVIDENCE</a>
      </div>
      <div class="div-block-22">
        <a href="#overview" class="button w-button sidenav-link"></a>
        <a href="#methods" class="button w-button sidenav-link"></a>
        <a href="#current-state" class="button w-button sidenav-link"></a>
        <a href="#future-state" class="button w-button sidenav-link"></a>
        <a href="#insights" class="button w-button sidenav-link"></a>
        <a href="#evidence" class="button w-button sidenav-link"></a>
      </div>
    </div>
    <div class="div-block-29">
      <div id="overview" data-w-id="9c2459a9-6b08-0e38-5d32-f3902443732b" class="div-block-7">
        <p class="paragraph-content">Our initial research goal was to understand the current state of content consumption and what users consider to be the integral elements of the TV viewing experience.</p>
        <ul role="list" class="icongridbase">
          <li id="w-node-_9c2459a9-6b08-0e38-5d32-f3902443732f-79f07093" class="icongrid">What do our users think TV is?</li>
          <li id="w-node-_9c2459a9-6b08-0e38-5d32-f39024437331-79f07093" class="icongrid">What are users’ current digital content consumption habits and experiences?</li>
          <li class="icongrid">How do people use, consume and view TV in their daily life?</li>
        </ul>
        <p class="paragraph-content">Keeping these questions in mind, we studied our users’ behaviors, observed their reactions to novel scenarios, and examined the potential user needs that are not currently being met. We realized that the lines between TV content and digital content has blurred, and that TV content now encompasses the bite-sized short multimedia clips accessible on everyday smartphones, as well as the video content available on streaming platforms and media outlets like YouTube. Consequently, we began by exploring the current state of digital content consumption and the digital content viewing experience. Using those findings, we then conducted a future-focused need-finding research to examine avenues in which the current state of digital TV could evolve to meet such needs.</p>
      </div>
      <div id="methods" data-w-id="81c7d69c-3d98-654d-31e9-3715fb8b68e1" class="div-block-15 main-col-div">
        <div id="w-node-fe383e66-a6db-63fe-4674-ec42df43d5a1-79f07093" data-w-id="fe383e66-a6db-63fe-4674-ec42df43d5a1" class="div-block-19">
          <ul role="list" class="list-3">
            <li class="list-item-5">Affinity Diagramming</li>
            <li class="list-item-6">Think Aloud Protocol</li>
            <li class="list-item-7">Directed Storytelling</li>
            <li class="list-item-8">Contextual Inquiry</li>
            <li class="list-item-9">Experience Mapping</li>
          </ul>
        </div>
        <div id="w-node-f4d20c5b-d84a-5ec5-0056-73038a5859b8-79f07093" class="div-block-16">
          <ul role="list" class="list-3">
            <li class="list-item-10">Diary Study</li>
            <li class="list-item-11">Conceptual Prototyping</li>
            <li class="list-item-12">Bodystorming</li>
            <li class="list-item-13">The Thing from the Future</li>
            <li class="list-item-14">Wizard of Oz Techniques</li>
          </ul>
        </div>
      </div>
      <div id="current-state" data-w-id="254065a2-5f4c-8b9c-cd26-3cc851953d2c" class="div-block-7">
        <h1 class="heading-3">CURRENT STATE</h1>
        <div class="div-block-17"><img src="images/pretotype1.JPG" loading="lazy" id="w-node-a9343d1b-4204-9282-1bd8-ef2dd3755ac2-79f07093" sizes="(max-width: 479px) 90vw, (max-width: 991px) 65vw, (max-width: 4554px) 24vw, 1093px" srcset="images/pretotype1-p-500.jpeg 500w, images/pretotype1.JPG 1093w" alt="">
          <p class="paragraph-2">We began with a larger scale investigation to feel out the sheer scope of a project this size. A quickly constructed “pretotype” involving a TV that would follow a user’s eyeline as they completed tasks or shifted in their bed or couch and a 3D video accompanied by faking surround sound gave us our base impressions on how people instinctively interacted with novel technologies in television when not given discrete controls.</p>
        </div>
        <div class="div-block-18"><img src="images/ResearchPrototype_1.png" loading="lazy" sizes="(max-width: 479px) 90vw, (max-width: 991px) 65vw, 50vw" srcset="images/ResearchPrototype_1-p-500.png 500w, images/ResearchPrototype_1.png 782w" alt="" class="image-12">
          <p class="paragraph-5">A member of our team wandered into the participants view wearing a square of post-its. When our participants didn’t notice the attention check, we could confirm satisfactory levels of immersion.</p>
        </div>
        <p class="paragraph-content">This supplemented with participant reports on viewing habits and preferences in a focused 60 minute contextual inquiry, and reported over a 7 day diary study period provided the foundation of our first affinity diagram,. Here, we collected notes and found patterns, overlapping feelings, frustrations, and surfacing wants and needs based on the current state of television.</p><img src="images/ResearchPrototype_2.png" loading="lazy" sizes="(max-width: 479px) 90vw, (max-width: 767px) 250px, (max-width: 991px) 54vw, 58vw" srcset="images/ResearchPrototype_2-p-500.png 500w, images/ResearchPrototype_2.png 793w" alt="" class="image">
      </div>
      <div id="future-state" data-w-id="28b2cd3b-6f22-7ec2-ceef-a6d9a0300004" class="div-block-7">
        <h1 class="heading-3">FUTURE STATE</h1>
        <p class="paragraph-content">To supplement the research we had done on the current state of TV, we began looking towards forward with the future-thinking game <a href="http://situationlab.org/project/the-thing-from-the-future/" data-w-id="4aebea32-58bd-a056-8773-9c03d3447b98" style="color:rgb(103,131,230)" target="_blank" class="link-6"><span class="text-span-17">The Thing From the Future</span></a>, adapted for our purpose with cards dedicated to TV, digital media, and emerging technologies.</p>
        <div class="div-block-18"><img src="images/ResearchPrototype_3.png" loading="lazy" sizes="(max-width: 479px) 90vw, (max-width: 991px) 65vw, 50vw" srcset="images/ResearchPrototype_3-p-500.png 500w, images/ResearchPrototype_3.png 749w" alt="" class="image-12">
          <p class="paragraph-5">Adapted item cards to pivot the Situation Lab&#x27;s Thing From the Future Game for our purposes - the TV (and Emerging Tech) Thing From the Future</p>
        </div>
        <p class="paragraph-content">User-generated solutions to the prompts gave us insight into what people envisioned for themselves in the future and unearthed wants and needs in a tech-driven future. Broadly a couple of these were:</p>
        <div class="div-block-20"><img src="images/ResearchPrototype_Quote1.png" loading="lazy" id="w-node-_7b437105-dd32-7ff7-ec94-5d520a8066b9-79f07093" alt="">
          <div>
            <h1 class="heading-4">Escapism</h1>
          </div><img src="images/ResearchPrototype_Quote2.png" loading="lazy" id="w-node-_07c0cc70-ed3d-c140-5164-a71225e6b270-79f07093" alt="">
          <div>
            <div>
              <h1 class="heading-4">Nostalgia</h1>
            </div>
          </div><img src="images/ResearchPrototype_Quote3.png" loading="lazy" id="w-node-_2bb12750-e32d-d293-ff84-bc1f8af2898b-79f07093" alt="">
          <div>
            <div>
              <h1 class="heading-4">Collective Experiences</h1>
            </div>
          </div>
        </div>
      </div>
      <div id="insights" data-w-id="03440689-c2cd-ca48-9f75-5c46ff05ca76" class="main-col-div">
        <ol role="list" class="list-4">
          <li id="w-node-_62d000f3-c963-f4af-9489-78e9373e4479-79f07093" class="list-item">People want to have <span><strong class="bold-text-6">collective experiences</strong></span> when watching with other people</li>
          <li class="list-item-2">People choose to watch TV because they can <strong class="bold-text-6">easily switch their attention</strong> to and from other tasks</li>
          <li class="list-item-3">People want <strong class="bold-text-6">gratification from the TV content</strong> and not the process of obtaining it</li>
          <li class="list-item-4">People want to use content to <strong class="bold-text-16">indulge in their emotions</strong></li>
        </ol>
      </div>
      <div id="evidence" data-w-id="3d4b3f9c-d7b4-d835-f340-f2bc3b7daa3a" class="main-col-div"><img src="images/ResearchPrototype_PainPoints.png" loading="lazy" data-w-id="37e7f955-1c1c-5bc0-5656-e00295c66938" sizes="(max-width: 479px) 74vw, (max-width: 767px) 60vw, (max-width: 991px) 48vw, 52vw" srcset="images/ResearchPrototype_PainPoints-p-500.png 500w, images/ResearchPrototype_PainPoints.png 802w" alt="" class="image-3"></div>
    </div>
  </div>
  <div class="page-background content">
    <div style="opacity:0" class="background-color"></div>
    <div class="_3d-scene"></div>
  </div>
  <div data-collapse="medium" data-animation="default" data-duration="400" role="banner" class="navbar w-nav">
    <div class="container-6 w-container">
      <nav role="navigation" class="nav-menu w-nav-menu">
        <div class="navlink_wrap">
          <a href="index.html" data-w-id="186b109c-df66-3204-ca73-fb6ba9fc7719" class="navbar-link w-nav-link" data-index="0">Home</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
        <div class="navlink_wrap">
          <a href="solution.html" data-w-id="186b109c-df66-3204-ca73-fb6ba9fc771d" class="navbar-link w-nav-link" data-index="1">Solution</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
        <div class="div-block-26">
          <div data-hover="1" data-delay="0" class="dropdown w-dropdown">
            <div class="dropdown-toggle navlink_wrap w-dropdown-toggle">
              <div class="dropdown-text">process</div>
            </div>
            <nav class="dropdown-list w-dropdown-list">
              <a href="process.html" data-w-id="186b109c-df66-3204-ca73-fb6ba9fc772a" style="color:rgb(103,131,230)" aria-current="page" class="dropdown-link w-dropdown-link w--current navbar-link" data-index="2">Research</a>
              <a href="process-prototyping.html" data-w-id="186b109c-df66-3204-ca73-fb6ba9fc772c" style="color:rgb(103,131,230)" class="dropdown-link w-dropdown-link navbar-link" data-index="3">Prototyping</a>
            </nav>
          </div>
        </div>
        <div class="navlink_wrap">
          <a href="team.html" data-w-id="186b109c-df66-3204-ca73-fb6ba9fc7721" class="navbar-link w-nav-link" data-index="4">team</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
        <div class="navlink_wrap">
          <a href="https://interdigitalatcmu.medium.com/" data-w-id="186b109c-df66-3204-ca73-fb6ba9fc772f" target="_blank" class="navbar-link w-nav-link" data-index="3">blog</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
      </nav>
      <div class="menu-button w-nav-button">
        <div class="icon w-icon-nav-menu"></div>
      </div>
    </div>
  </div>
  <div class="home-section-spacer bottom-nav wf-section">
    <a href="process-prototyping.html" id="w-node-_09d4a494-049c-7714-215f-54bf8202d18f-79f07093" class="link-2"><span class="text-span-15">Our prototyping →</span></a>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=607dcf321ef9c11104c38e66" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script>
  <script type="module">
    // Find the latest version by visiting https://unpkg.com/three.          
    import * as THREE from 'https://unpkg.com/three@0.127.0/build/three.module.js';
    import { GUI } from 'https://unpkg.com/three@0.127.0/examples/jsm/libs/dat.gui.module.js';
    import { GLTFLoader } from 'https://unpkg.com/three@0.127.0/examples/jsm/loaders/GLTFLoader.js';
    import { EffectComposer } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/EffectComposer.js';
    import { RenderPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/RenderPass.js';
    import { UnrealBloomPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/UnrealBloomPass.js';
    import { SSAOPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/SSAOPass.js';
    import Stats from 'https://unpkg.com/three@0.127.0/examples/jsm/libs/stats.module';

    const loader = new GLTFLoader();

    const scene = new THREE.Scene();
    loader.load('./Models/WebsiteScene.glb', function(gltf) {
        console.log(gltf.scene);
        scene.add(gltf.scene);
        configGLTBScene();
        init();
        animate();
        gsap.to(".content", {css: {backgroundColor: "rgba(0,0,0,0.4)"}, delay: 2})
    })

    // let stats = new Stats();

    const fov = 80;
    const aspect = 1.8;  // the canvas default
    const near = 0.1;
    const far = 1000;
    const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
    let cameraPosition = new THREE.Vector3(0, 2, 10);
    let cameraLookAtPosition = new THREE.Vector3(0, 0, 0); // TODO: Lerp between objects via tweening
    let lookAtObject = new THREE.Object3D();

    camera.position.set(cameraPosition.x, cameraPosition.y, cameraPosition.z);
    var renderer = new THREE.WebGLRenderer({
        antialias: true,
        alpha: true
    });

    var canvas = renderer.domElement;
    document.body.appendChild(canvas);

    var plane = new THREE.Plane(new THREE.Vector3(0, 0, 1), -10);
    var raycaster = new THREE.Raycaster();
    var mouse = new THREE.Vector2();
    var look = new THREE.Vector2();
    var pointOfIntersection = new THREE.Vector3();

    document.addEventListener("mousemove", onMouseMove, false);

    const PPParams = {
        exposure: 1,
        bloomStrength:  0.7,
        bloomThreshold: 0,
        bloomRadius: 0
    };

    function onMouseMove(event){
        mouse.x = ( event.clientX / window.innerWidth ) * 2 - 1;
        mouse.y = - ( event.clientY / window.innerHeight ) * 2 + 1;
    }

    let videoTextIDs = {}
    function configGLTBScene() {
        // Set floor color
        scene.getObjectByName('Floor', true).material.color.setHex(0xF1F0E4);

        // RESEARCH PAGE
        // Set couch material color
        for (let i = 0; i < 12; i++) {
            scene.getObjectByName(`Couch_${i+1}`, true).material.color.setHex(0x6A2E35);
        }

        // Set coffee table material color
        scene.getObjectByName('CoffeeTableSurface', true).material = new THREE.MeshLambertMaterial({color: 0xDDA77B});
        scene.getObjectByName('CoffeeTableLegs', true).material = new THREE.MeshLambertMaterial({color: 0x283845});
        scene.getObjectByName('CoffeeTableSupports', true).material = new THREE.MeshLambertMaterial({color: 0x283845});

        // TV Stand Cabinets
        let cabinetMat = new THREE.MeshLambertMaterial({color: 0xB6C2D9});
        let surfaceMat = new THREE.MeshLambertMaterial({color: 0x171D1C})
        scene.getObjectByName('236obj05', true).material = surfaceMat;
        scene.getObjectByName('236obj04', true).material = cabinetMat;
        scene.getObjectByName('236obj02', true).material = cabinetMat;
        scene.getObjectByName('Mesh457', true).material = cabinetMat;

        video = document.getElementById( 'mainTV' );
        video.play();

        texture = new THREE.VideoTexture( video );
        scene.getObjectByName("SonyTVScreen", true).material = new THREE.MeshLambertMaterial( { map:  texture } );
    }

    let video, texture, deepFake, df_texture, material, mesh, box, composer, effectFXAA;
    function initDebugGUI() {
      const gui = new GUI();

      gui.add( PPParams, 'exposure', 0.1, 2 ).onChange( function ( value ) {

          renderer.toneMappingExposure = Math.pow( value, 4.0 );

      } );

      gui.add( PPParams, 'bloomThreshold', 0.0, 1.0 ).onChange( function ( value ) {

          bloomPass.threshold = Number( value );

      } );

      gui.add( PPParams, 'bloomStrength', 0.0, 3.0 ).onChange( function ( value ) {

          bloomPass.strength = Number( value );

      } );

      gui.add( PPParams, 'bloomRadius', 0.0, 1.0 ).step( 0.01 ).onChange( function ( value ) {

          bloomPass.radius = Number( value );

      } );

      gui.open();
    }


    function init() {
        lookAtObject.position.x = 0; lookAtObject.position.y = 0; lookAtObject.position.z = 0; 
        scene.add(lookAtObject)

        const color = 0x0;
        const density = 0.1;
        scene.fog = new THREE.FogExp2(color, density);

        // POST PROCESSING
        const renderScene = new RenderPass( scene, camera );
        const bloomPass = new UnrealBloomPass( new THREE.Vector2( window.innerWidth, window.innerHeight ), 1.5, 0.4, .85 );
        bloomPass.threshold = PPParams.bloomThreshold;
        bloomPass.strength = PPParams.bloomStrength;
        bloomPass.radius = PPParams.bloomRadius;
        renderer.setSize(window.innerWidth, window.innerHeight);

        const ssaoPass = new SSAOPass( scene, camera, window.innerWidth, window.innerHeight );
        ssaoPass.kernelRadius = 16;
        renderer.setClearColor( color, 1 );

        composer = new EffectComposer( renderer );
        composer.addPass( renderScene );
        composer.addPass( bloomPass );
        // composer.addPass(ssaoPass);

        // document.body.appendChild(stats.dom);
        // document.body.addEventListener('keydown', keyPressed);
        document.body.addEventListener('resize', onWindowResize)

        setupTween();
        SetCameraSpotlight($('body').data("index"));
        // initDebugGUI();
    }

    var easeAmount = 8;
    var sensitivity = 0.0005;
    function update() {
        if (spotLightHelper) spotLightHelper.update();
        lookAtObject.position.x = cameraLookAtPosition.x;
        lookAtObject.position.y = cameraLookAtPosition.y;
        lookAtObject.position.z = cameraLookAtPosition.z;

        look.x += (mouse.x-look.x)/easeAmount;
        look.y += (mouse.y-look.y)/easeAmount;
        
        camera.position.x = cameraPosition.x + look.x * window.innerWidth * sensitivity;
        camera.position.y = cameraPosition.y + look.y * window.innerHeight * sensitivity;
        camera.position.z = cameraPosition.z;

        camera.lookAt(lookAtObject.position);
        // stats.update();
        TWEEN.update();
    }

    function animate() 
    {
        requestAnimationFrame( animate );
        composer.render();
        // render();		
        update();
    }

    function render() 
    {	
        if ( video.readyState === video.HAVE_ENOUGH_DATA ) 
        {
            if ( texture ) 
                texture.needsUpdate = true;
        }

        if (resize(renderer)) {
            camera.aspect = canvas.clientWidth / canvas.clientHeight;
            camera.updateProjectionMatrix();
        }

        renderer.render( scene, camera );
    }

    function resize(renderer) {
        const canvas = renderer.domElement;
        const width = canvas.clientWidth;
        const height = canvas.clientHeight;
        const needResize = canvas.width !== width || canvas.height !== height;
        if (needResize) {
            renderer.setSize(width, height, false);
        }
        return needResize;
    }

    function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize( window.innerWidth, window.innerHeight );
    }

    // function keyPressed(e) {
    //     switch(e.key) {
    //         case 'ArrowLeft':
    //             console.log("Arrow Left");
    //             cameraTweenIndex = cameraTweenIndex - 1 < 0 ? cameraSpotlightConfig.length - 1 : cameraTweenIndex - 1;
    //             updateCameraTransform();
    //             updateSpotlight();
    //             break;
    //         case 'ArrowRight':
    //             console.log("Arrow Right");
    //             cameraTweenIndex = cameraTweenIndex + 1 >= cameraSpotlightConfig.length ? 0 : cameraTweenIndex + 1;
    //             updateCameraTransform();
    //             updateSpotlight();
    //             break;
    //     }
    //     e.preventDefault();
    // }

    function SetCameraSpotlight(newTweenIndex) {
        cameraTweenIndex = newTweenIndex;
        updateCameraTransform();
        updateSpotlight();
    }

    let cameraSpotlightConfig = [
        {
            focusObj: "FutureTV",
            positionName: "Position_Main",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "CinemaScreen",
            positionName: "Position_Solution",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "SonyTV",
            positionName: "Position_Research",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "ComputerScreen",
            positionName: "Position_Prototype",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 1.5,
        },
        {
            focusObj: "TeamPanel",
            positionName: "Position_About",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 1.5,
        }
    ]

    let default_color = 0xF1F0E4;
    let cameraTweenIndex = 0;
    let spotlight, spotLightHelper;
    function setupTween() {
        TWEEN.removeAll();

        spotlight = createSpotlight(default_color);
        scene.add(spotlight);

        // spotLightHelper = new THREE.SpotLightHelper( spotlight );
        // scene.add( spotLightHelper );

        cameraSpotlightConfig.forEach((config, i) => {
            // console.log(config);
            let obj = scene.getObjectByName(config.focusObj, true);
            const camPos = scene.getObjectByName(config.positionName, true).position;
            config.lookAt = new THREE.Vector3(obj.position.x, obj.position.y, obj.position.z);
            config.cameraPos = new THREE.Vector3(camPos.x, camPos.y, camPos.z);
        })
    }

    function updateCameraTransform() {
        const temp = cameraSpotlightConfig[cameraTweenIndex];

        let tempPos = cameraPosition;
        let newCamPos = temp.cameraPos;
        let tempLookAt = lookAtObject.position;
        let newLookAt = temp.lookAt;

        // console.log(newCamPos);

        new TWEEN.Tween(tempPos)
        .to(newCamPos, 2000)
        .easing (TWEEN.Easing.Cubic.InOut)
        .onUpdate(function() { cameraPosition = tempPos; })
        .start();

        new TWEEN.Tween(tempLookAt)
        .to(newLookAt, 2000)
        .easing (TWEEN.Easing.Cubic.InOut)
        .onUpdate(function() { cameraLookAtPosition = tempLookAt; })
        .start();
    }

    function createSpotlight(color) {
        const newObj = new THREE.SpotLight(color, 2);

        newObj.castShadow = true;
        newObj.angle = 0.5;
        newObj.penumbra = 0.5;
        newObj.decay = 2;
        newObj.distance = 20;
        newObj.target = lookAtObject;

        return newObj;
    }

    function updateSpotlight() {
        const temp = cameraSpotlightConfig[cameraTweenIndex];
        console.log(temp);

        let tempPosition = spotlight.target.position;
        let tempIntensity = spotlight.intensity;

        new TWEEN.Tween(spotlight.position)
        .to({x: temp.cameraPos.x, y: 10, z: temp.cameraPos.z}, 1000)
        .easing(TWEEN.Easing.Cubic.InOut)
        .start();

        spotlight.color.setHex(temp.lightColor);
        spotlight.intensity = temp.lightIntensity;
    }

    window.addEventListener( 'resize', function () {
			  camera.aspect = window.innerWidth / window.innerHeight;
			  camera.updateProjectionMatrix();
			  renderer.setSize( window.innerWidth, window.innerHeight );
			}, false );

    $('.navbar-link').on('click', function(e) {
        e.preventDefault();
        if ($(this).data("index") !== undefined && $(this).data("index") !== null) {
          SetCameraSpotlight($(this).data("index"));
          if (!this.href.includes("#") && !this.href.includes('interdigitalatcmu.medium.com')) {
            gsap.to(".content", {css: {backgroundColor: "rgba(0,0,0,1)"}, duration: 0.5})
            setTimeout(() => {
              window.location = this.href
            }, 1000);
          }
          else {
            window.open(this.href, '_blank');
          }
        }
    })

    $('.menuitem-link-2').on('click', function(e) {
      e.preventDefault();
      SetCameraSpotlight($(this).data("index"));
    })

    $('.home-menu-title').hover(function(e) {
      gsap.to($(this), {css: {color: '#6783E6'}, duration: 0.25});
    }, function(e) {
      if ($(this).hasClass('current-nav')) {
        gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
      }
      else {
        gsap.to($(this), {css: {color: '#f1f0e4'}, duration: 0.25});
      }
    })

    $('#process_dropdown').hover(function(e) {
      $('#nav_dropdown').css('display', 'block');
    }, function(e) {
      $('#nav_dropdown').css('display', 'none');
    })

    $('.navbar-link').hover(function(e) {
      gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
    }, function(e) {
      if ($(this).hasClass('current-nav')) {
        gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
      }
      else {
        gsap.to($(this), {css: {color: '#f1f0e4'}, duration: 0.25});
      }
    })
  </script>
  <script type="text/javascript" src="js/gsap_anchor.js"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
</body>
</html>