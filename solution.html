<!DOCTYPE html><!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Tue Aug 10 2021 20:07:52 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="607dcfeb8fffbb3fff0cab12" data-wf-site="607dcf321ef9c11104c38e66">
<head>
  <meta charset="utf-8">
  <title>Solution | The Future of Digital Television</title>
  <meta content="Solution | The Future of Digital Television" property="og:title">
  <meta content="Solution | The Future of Digital Television" property="twitter:title">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/interdigital.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inter:100,200,300,regular,500,600,700,800,900","Space Grotesk:300,regular,500,600,700"]  }});</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tween.js/16.3.5/Tween.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.6.1/gsap.min.js" integrity="sha512-cdV6j5t5o24hkSciVrb8Ki6FveC2SgwGfLE31+ZQRHAeSRxYhAQskLkq3dLm8ZcWe1N3vBOEYmmbhzf7NTtFFQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.7.1/ScrollTrigger.min.js" integrity="sha512-DlTk2PLUinhBupE89kHOJTt11QqbRMQVlbb26XVDvp4D1kt0fRvQJslvZnTelRJHq6yK0tIPCR7cul8+9Blz0g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.7.1/ScrollToPlugin.min.js" integrity="sha512-1OG9UO4krPizjtz/c9iDbjCqtXznBYdJeD4ccPaYfJHzC6F1qoQ3P1bgQ3J8lgCoK5qGVCqsY4+/RKjLDzITVQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inconsolata:400,700","Inter:100,200,300,regular,500,600,700,800,900","Space Grotesk:300,regular,500,600,700"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
</head>
<body class="body-4" data-index="1">
  <video id="prototypeTV" autoplay muted loop crossOrigin="anonymous" style="display:none">
    <source src="./Textures/SolutionTexture.mp4" type='video/mp4'>
  </video>
  <div data-w-id="9f127bba-7910-e9b4-6ae4-061e5576012f" class="title-section op-title-section wf-section">
    <h1 class="title-card">SOLUTION<br><strong class="bold-text-11">Context-Aware Content</strong></h1>
  </div>
  <div class="scroll-ind-section wf-section">
    <div class="scroll-ind-div">
      <div data-w-id="d729da5b-a4a9-923b-6253-32f7e48efe03" data-animation-type="lottie" data-src="documents/lf30_editor_rdgpmu2e.json" data-loop="1" data-direction="1" data-autoplay="1" data-is-ix2-target="0" data-renderer="svg" data-default-duration="3" data-duration="0" class="scroll_lottie"></div>
    </div>
  </div>
  <div class="content-section toc-section wf-section">
    <div class="div-block-7">
      <h3 class="paragraph-heading heading-space-long">A future of...</h3>
      <div class="w-layout-grid grid">
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">01</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text">Convenience</div>
          </div>
        </div>
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">02</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text">Personalization</div>
          </div>
        </div>
        <div class="toc-column w-row">
          <div class="w-col w-col-3">
            <div class="toc-index">03</div>
          </div>
          <div class="w-col w-col-9">
            <div class="toc-text">Socialization</div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div id="goto-convenience" class="content-section wf-section">
    <div id="navigation-anchor" class="side-nav-div">
      <div class="div-block-24">
        <a href="#overview" class="sidenav-link">OVERVIEW</a>
        <a href="#emotion-based" class="sidenav-link">EMOTION-BASED ADAPTATION</a>
        <a href="#attention-based" class="sidenav-link">ATTENTION-BASED ADAPTATION</a>
        <a href="#secure-data" class="sidenav-link">SECURE DATA USAGE &amp; STORAGE</a>
        <a href="#experience" class="sidenav-link">EXPERIENCE OUR FINAL PROTOTYPE</a>
      </div>
      <div class="div-block-22">
        <a href="#overview" class="button w-button sidenav-link"></a>
        <a href="#emotion-based" class="button w-button sidenav-link"></a>
        <a href="#attention-based" class="button w-button sidenav-link"></a>
        <a href="#secure-data" class="button w-button sidenav-link"></a>
        <a href="#experience" class="button w-button sidenav-link"></a>
      </div>
    </div>
    <div class="div-block-27">
      <div id="overview" data-w-id="2e6b10ab-8772-3f78-3e68-25440cbde9dc" class="main-col-div">
        <p class="paragraph-content">Combining our insights from the <a href="process.html"><strong class="bold-text-17">research</strong></a><strong class="bold-text-17"> </strong>and <a href="process-prototyping.html"><strong class="bold-text-18">prototyping </strong></a>stages, we present <span class="text-span-16">AdaptiveWatch</span>- a future-focused TV viewing experience we envision would be integrated as a togglable feature across all TV streaming platforms. AdaptiveWatch utilizes user-purchased sensors, such as smartwatches, cameras, and smart-speakers to extract user’s emotion, attention, and personal viewing habits. Using that information, it will leverage Deep Learning models to synthetically adapt the TV content in real time based on the user’s context, thereby seamlessly and dynamically adjusting the TV content to meet the user’s emotional, cognitive, and personal viewing needs.</p>
      </div>
      <div id="emotion-based" data-w-id="4e245fbd-5afd-f33d-0806-9851433fcbeb" class="main-col-div"><img src="images/LRRH.gif" loading="lazy" alt="An animation of Little Red Riding Hood and her mother. The scene changes between being dark, rainy, and gloomy to light and sunny to show the difference between the Scary, Sad, and Happy narratives" class="image-14">
        <p class="paragraph-5">AdaptiveWatch uses real-time stylistic changes to the plot-line, weather, music, and color grading to adapt the content according to the user&#x27;s  emotion and personal viewing preferences to enhance the TV viewing experience.</p>
        <p class="paragraph-content">Our previous research found that people have a desire to immerse themselves in virtual environments based on their mood or current emotional state. Whether the user’s goal is to wallow in their sadness or counteract it with something happy, AdaptiveWatch will be able to <span><strong class="bold-text-19">adapt the plotline and the scene styles</strong></span> through Deep Learning to better the TV viewing experiences. AdaptiveWatch references literature and psychology research to map certain color changes, music changes, and weather changes to human emotions. In addition, by tracking user’s historical viewing preferences, AdaptiveWatch leverages Deep Learning to synthetically alter the plotline. It will either incorporate narratives and features that the user has historically enjoyed, or censor and remove narratives that the user may dislike based on prior viewing experiences. Play with our interactive prototypes below to see how AdaptiveWatch can be integrated with existing TV streaming services.</p><a href="https://www.figma.com/proto/2qrLxmZVKsDGewqc40tpqE/MHCI-Capstone-Interdigital?page-id=6539%3A311&node-id=6540%3A311&viewport=137%2C335%2C0.02379891462624073&scaling=scale-down&starting-point-node-id=6540%3A311&show-proto-sidebar=1" target="_blank"><img src="images/Frame-1-3.png" loading="lazy" sizes="(max-width: 479px) 74vw, (max-width: 767px) 75vw, (max-width: 991px) 60vw, 597px" srcset="images/Frame-1-3-p-500.png 500w, images/Frame-1-3.png 597w" alt="" class="image-24"></a>
      </div>
      <div id="attention-based" data-w-id="93e020ac-b923-7c09-bb8b-c15de0138ca1" class="main-col-div">
        <p class="paragraph-content">Growing numbers of users have begun to think of TV as a secondary, or background activity. Part of what makes it so appealing is that it requires no active input once you get started watching. However, there are times when might need to manually pause the show in order to reply to a message or check on food in the kitchen. Our system detects your activity automatically while you are watching tv and adapts the content accordingly, either <span><strong class="bold-text-20">pausing or changing to audio narration format</strong></span>, so you never miss any part of the show.</p><img src="images/Solution_1.png" loading="lazy" sizes="(max-width: 479px) 74vw, (max-width: 767px) 75vw, (max-width: 991px) 60vw, (max-width: 2176px) 52vw, 1132px" srcset="images/Solution_1-p-800.png 800w, images/Solution_1-p-1080.png 1080w, images/Solution_1.png 1132w" alt="A diagram shows that tasks that require a higher cognitive load prefer pausing the content and lower cognitive load tasks prefer an audio description" class="image-13">
      </div>
      <div id="secure-data" data-w-id="405c5503-f7b7-cbb2-cee3-0ddd6914e283" class="main-col-div">
        <p class="paragraph-content">Personal data privacy concerns came up several times in our user study and the majority of the <strong class="bold-text-23">users want to be in the driver’s seat to determine when and how the content would be adapted</strong>. On the other hand, we realized <strong class="bold-text-24">users also expressed frustrations when manually inputting their emotions into the system</strong>, as it distracted them from the TV viewing experience, and required them to consciously think about how they felt at pivotal moments in the TV content. <br><br>To resolve these conflicting pain points users have expressed, we envision a future where users will feel more comfortable adopting emerging and existing smart technologies to track their emotions. However, to ensure that TV users are comfortable during the early stages of adopting AdaptiveWatch, we have provided users with manual controls that they can use to dictate their TV viewing experience. With our AdaptiveWatch system, users can toggle on and off the system whenever they want to during their viewing session, so they can enjoy contents from the artist’s original intention or personalized versions tailored to their preferences.<br><br>User’s historical viewing data has also been integral towards personalizing the TV viewing experience. Prior prototyping suggested that strictly looking at user’s emotions and attention was insufficient, because different users liked and disliked different aspects of the show, ranging from the visual elements of the TV content to specific elements in the plot and narratives. To further personalize the TV viewing experience, AdaptiveWatch will leverage user’s historic viewing data to track what shows they have enjoyed or disliked, and how they have reacted emotionally to certain shows. Using that data, AdaptiveWatch will <strong class="bold-text-21">further adapt and tailor the TV content synthetically to their personal viewing preferences</strong>. To address data privacy concerns, AdaptiveWatch will stored the data safely on a local system that is <strong class="bold-text-22">dedicated to enhancing user’s TV viewing experience</strong>, and users will be able to control when and how these data can be used for their viewing experience.</p>
      </div>
      <div id="experience" data-w-id="6f14d2c8-be25-5521-6585-b9cd267d0afe" class="main-col-div">
        <!-- <div class="div-block-28"><img src="images/ezgif.com-gif-maker-5.gif" loading="lazy" alt="A cursor moves around a page selecting adaptive watch options on Hulu" class="image-23"></div> -->
        <div class="div-block-28"><iframe style="width: 100%; min-height: 50vh"
          src="https://www.youtube.com/embed/_s2QyFCjOqw">
          </iframe></div>
        <p class="paragraph-content"><br>We put a spin on the classic European fairy tale Little Red Riding Hood. The narrative that we all know- a little young girl who visited her grandmother in the woods but they both got eaten by a wolf, and then were rescued by a hunter passing by- is the <strong class="bold-text-12">base narrative</strong> that we have. On top of the base narrative, we created <strong class="bold-text-13">three</strong> other narratives which are <strong class="bold-text-14">sad, horror, and happy</strong> in order to simulate on-the-fly plot adaptation based on users’ emotional inputs. Aside from the plot-line adaption, we have also incorporated <span class="text-span-13"><strong>stylistic changes</strong></span> including weather, background music, and colors to see which change(s) users prefer to have during their viewing session.</p>
      </div>
    </div>
  </div>
  <div class="page-background content">
    <div style="opacity:0" class="background-color"></div>
    <div class="_3d-scene"></div>
  </div>
  <div data-collapse="medium" data-animation="default" data-duration="400" role="banner" class="navbar w-nav">
    <div class="container-6 w-container">
      <nav role="navigation" class="nav-menu w-nav-menu">
        <div class="navlink_wrap">
          <a href="index.html" data-w-id="2b2f6d42-474b-79ff-c7f4-584934c889f6" class="navbar-link w-nav-link" data-index="0">Home</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
        <div class="navlink_wrap">
          <a href="solution.html" data-w-id="2b2f6d42-474b-79ff-c7f4-584934c889fa" aria-current="page" class="navbar-link w-nav-link w--current" data-index="1">Solution</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
        <div class="div-block-26">
          <div data-hover="1" data-delay="0" class="dropdown w-dropdown">
            <div class="dropdown-toggle navlink_wrap w-dropdown-toggle">
              <div class="dropdown-text">process</div>
            </div>
            <nav class="dropdown-list w-dropdown-list">
              <a href="process.html" data-w-id="2b2f6d42-474b-79ff-c7f4-584934c88a07" style="color:rgb(103,131,230)" class="dropdown-link w-dropdown-link navbar-link" data-index="2">Research</a>
              <a href="process-prototyping.html" data-w-id="2b2f6d42-474b-79ff-c7f4-584934c88a09" style="color:rgb(103,131,230)" class="dropdown-link w-dropdown-link navbar-link" data-index="3">Prototyping</a>
            </nav>
          </div>
        </div>
        <div class="navlink_wrap">
          <a href="team.html" data-w-id="2b2f6d42-474b-79ff-c7f4-584934c889fe" class="navbar-link w-nav-link" data-index="4">team</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
        <div class="navlink_wrap">
          <a href="https://interdigitalatcmu.medium.com/" data-w-id="2b2f6d42-474b-79ff-c7f4-584934c88a0c" target="_blank" class="navbar-link w-nav-link" data-index="1">blog</a>
          <div style="-webkit-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(-100%, 0, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="navlink_underline"></div>
        </div>
      </nav>
      <div class="menu-button w-nav-button">
        <div class="icon w-icon-nav-menu"></div>
      </div>
    </div>
  </div>
  <div class="home-section-spacer bottom-nav wf-section">
    <a href="process.html" id="w-node-d1d98938-ee17-141d-4faf-ff19d536242e-ff0cab12" class="link-2"><span class="text-span-15">Our research →</span></a>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=607dcf321ef9c11104c38e66" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script>
  <script type="module">
    // Find the latest version by visiting https://unpkg.com/three.          
    import * as THREE from 'https://unpkg.com/three@0.127.0/build/three.module.js';
    import { GUI } from 'https://unpkg.com/three@0.127.0/examples/jsm/libs/dat.gui.module.js';
    import { GLTFLoader } from 'https://unpkg.com/three@0.127.0/examples/jsm/loaders/GLTFLoader.js';
    import { EffectComposer } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/EffectComposer.js';
    import { RenderPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/RenderPass.js';
    import { UnrealBloomPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/UnrealBloomPass.js';
    import { SSAOPass } from 'https://unpkg.com/three@0.127.0/examples/jsm/postprocessing/SSAOPass.js';
    import Stats from 'https://unpkg.com/three@0.127.0/examples/jsm/libs/stats.module';

    const loader = new GLTFLoader();

    const scene = new THREE.Scene();
    loader.load('./Models/WebsiteScene.glb', function(gltf) {
        console.log(gltf.scene);
        scene.add(gltf.scene);
        configGLTBScene();
        init();
        animate();
        gsap.to(".content", {css: {backgroundColor: "rgba(0,0,0,0.4)"}, delay: 2})
    })

    // let stats = new Stats();

    const fov = 80;
    const aspect = 1.8;  // the canvas default
    const near = 0.1;
    const far = 1000;
    const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
    let cameraPosition = new THREE.Vector3(0, 2, 10);
    let cameraLookAtPosition = new THREE.Vector3(0, 0, 0); // TODO: Lerp between objects via tweening
    let lookAtObject = new THREE.Object3D();

    camera.position.set(cameraPosition.x, cameraPosition.y, cameraPosition.z);
    var renderer = new THREE.WebGLRenderer({
        antialias: true,
        alpha: true
    });

    var canvas = renderer.domElement;
    document.body.appendChild(canvas);

    var plane = new THREE.Plane(new THREE.Vector3(0, 0, 1), -10);
    var raycaster = new THREE.Raycaster();
    var mouse = new THREE.Vector2();
    var look = new THREE.Vector2();
    var pointOfIntersection = new THREE.Vector3();

    document.addEventListener("mousemove", onMouseMove, false);

    const PPParams = {
        exposure: 1,
        bloomStrength:  0.7,
        bloomThreshold: 0,
        bloomRadius: 0
    };

    function onMouseMove(event){
        mouse.x = ( event.clientX / window.innerWidth ) * 2 - 1;
        mouse.y = - ( event.clientY / window.innerHeight ) * 2 + 1;
    }

    let videoTextIDs = {}
    function configGLTBScene() {
        // Set floor color
        scene.getObjectByName('Floor', true).material.color.setHex(0xF1F0E4);

        // SOLUTIONS PAGE
        let LRRHText = new THREE.VideoTexture( document.getElementById('prototypeTV'));
        document.getElementById('prototypeTV').play();
        scene.getObjectByName('CinemaScreen', true).material = new THREE.MeshBasicMaterial({map: LRRHText});
        scene.getObjectByName('CinemaScreen', true).material.side = THREE.DoubleSide;
    }

    let video, texture, deepFake, df_texture, material, mesh, box, composer, effectFXAA;
    function initDebugGUI() {
      const gui = new GUI();

      gui.add( PPParams, 'exposure', 0.1, 2 ).onChange( function ( value ) {

          renderer.toneMappingExposure = Math.pow( value, 4.0 );

      } );

      gui.add( PPParams, 'bloomThreshold', 0.0, 1.0 ).onChange( function ( value ) {

          bloomPass.threshold = Number( value );

      } );

      gui.add( PPParams, 'bloomStrength', 0.0, 3.0 ).onChange( function ( value ) {

          bloomPass.strength = Number( value );

      } );

      gui.add( PPParams, 'bloomRadius', 0.0, 1.0 ).step( 0.01 ).onChange( function ( value ) {

          bloomPass.radius = Number( value );

      } );

      gui.open();
    }


    function init() {
        lookAtObject.position.x = 0; lookAtObject.position.y = 0; lookAtObject.position.z = 0; 
        scene.add(lookAtObject)

        const color = 0x0;
        const density = 0.1;
        scene.fog = new THREE.FogExp2(color, density);

        // POST PROCESSING
        const renderScene = new RenderPass( scene, camera );
        const bloomPass = new UnrealBloomPass( new THREE.Vector2( window.innerWidth, window.innerHeight ), 1.5, 0.4, .85 );
        bloomPass.threshold = PPParams.bloomThreshold;
        bloomPass.strength = PPParams.bloomStrength;
        bloomPass.radius = PPParams.bloomRadius;
        renderer.setSize(window.innerWidth, window.innerHeight);

        const ssaoPass = new SSAOPass( scene, camera, window.innerWidth, window.innerHeight );
        ssaoPass.kernelRadius = 16;
        renderer.setClearColor( color, 1 );

        composer = new EffectComposer( renderer );
        composer.addPass( renderScene );
        composer.addPass( bloomPass );
        // composer.addPass(ssaoPass);

        // document.body.appendChild(stats.dom);
        // document.body.addEventListener('keydown', keyPressed);
        document.body.addEventListener('resize', onWindowResize)

        setupTween();
        SetCameraSpotlight($('body').data("index"));
        // initDebugGUI();
    }

    var easeAmount = 8;
    var sensitivity = 0.0005;
    function update() {
        if (spotLightHelper) spotLightHelper.update();
        lookAtObject.position.x = cameraLookAtPosition.x;
        lookAtObject.position.y = cameraLookAtPosition.y;
        lookAtObject.position.z = cameraLookAtPosition.z;

        look.x += (mouse.x-look.x)/easeAmount;
        look.y += (mouse.y-look.y)/easeAmount;
        
        camera.position.x = cameraPosition.x + look.x * window.innerWidth * sensitivity;
        camera.position.y = cameraPosition.y + look.y * window.innerHeight * sensitivity;
        camera.position.z = cameraPosition.z;

        camera.lookAt(lookAtObject.position);
        // stats.update();
        TWEEN.update();
    }

    function animate() 
    {
        requestAnimationFrame( animate );
        composer.render();
        // render();		
        update();
    }

    function render() 
    {	
        if ( video.readyState === video.HAVE_ENOUGH_DATA ) 
        {
            if ( texture ) 
                texture.needsUpdate = true;
        }

        if (resize(renderer)) {
            camera.aspect = canvas.clientWidth / canvas.clientHeight;
            camera.updateProjectionMatrix();
        }

        renderer.render( scene, camera );
    }

    function resize(renderer) {
        const canvas = renderer.domElement;
        const width = canvas.clientWidth;
        const height = canvas.clientHeight;
        const needResize = canvas.width !== width || canvas.height !== height;
        if (needResize) {
            renderer.setSize(width, height, false);
        }
        return needResize;
    }

    function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize( window.innerWidth, window.innerHeight );
    }

    function SetCameraSpotlight(newTweenIndex) {
        cameraTweenIndex = newTweenIndex;
        updateCameraTransform();
        updateSpotlight();
    }

    let cameraSpotlightConfig = [
        {
            focusObj: "FutureTV",
            positionName: "Position_Main",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "CinemaScreen",
            positionName: "Position_Solution",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "SonyTV",
            positionName: "Position_Research",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 2,
        },
        {
            focusObj: "ComputerScreen",
            positionName: "Position_Prototype",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 1.5,
        },
        {
            focusObj: "TeamPanel",
            positionName: "Position_About",
            lookAt: null,
            cameraPos: null,
            lightColor: 0xF1F0E4,
            lightIntensity: 1.5,
        }
    ]

    let default_color = 0xF1F0E4;
    let cameraTweenIndex = 0;
    let spotlight, spotLightHelper;
    function setupTween() {
        TWEEN.removeAll();

        spotlight = createSpotlight(default_color);
        scene.add(spotlight);

        // spotLightHelper = new THREE.SpotLightHelper( spotlight );
        // scene.add( spotLightHelper );

        cameraSpotlightConfig.forEach((config, i) => {
            // console.log(config);
            let obj = scene.getObjectByName(config.focusObj, true);
            const camPos = scene.getObjectByName(config.positionName, true).position;
            config.lookAt = new THREE.Vector3(obj.position.x, obj.position.y, obj.position.z);
            config.cameraPos = new THREE.Vector3(camPos.x, camPos.y, camPos.z);
        })
    }

    function updateCameraTransform() {
        const temp = cameraSpotlightConfig[cameraTweenIndex];

        let tempPos = cameraPosition;
        let newCamPos = temp.cameraPos;
        let tempLookAt = lookAtObject.position;
        let newLookAt = temp.lookAt;

        // console.log(newCamPos);

        new TWEEN.Tween(tempPos)
        .to(newCamPos, 2000)
        .easing (TWEEN.Easing.Cubic.InOut)
        .onUpdate(function() { cameraPosition = tempPos; })
        .start();

        new TWEEN.Tween(tempLookAt)
        .to(newLookAt, 2000)
        .easing (TWEEN.Easing.Cubic.InOut)
        .onUpdate(function() { cameraLookAtPosition = tempLookAt; })
        .start();
    }

    function createSpotlight(color) {
        const newObj = new THREE.SpotLight(color, 2);

        newObj.castShadow = true;
        newObj.angle = 0.5;
        newObj.penumbra = 0.5;
        newObj.decay = 2;
        newObj.distance = 20;
        newObj.target = lookAtObject;

        return newObj;
    }

    function updateSpotlight() {
        const temp = cameraSpotlightConfig[cameraTweenIndex];
        console.log(temp);

        let tempPosition = spotlight.target.position;
        let tempIntensity = spotlight.intensity;

        new TWEEN.Tween(spotlight.position)
        .to({x: temp.cameraPos.x, y: 10, z: temp.cameraPos.z}, 1000)
        .easing(TWEEN.Easing.Cubic.InOut)
        .start();

        spotlight.color.setHex(temp.lightColor);
        spotlight.intensity = temp.lightIntensity;
    }

    window.addEventListener( 'resize', function () {
			  camera.aspect = window.innerWidth / window.innerHeight;
			  camera.updateProjectionMatrix();
			  renderer.setSize( window.innerWidth, window.innerHeight );
			}, false );

    $('.navbar-link').on('click', function(e) {
        e.preventDefault();
        if ($(this).data("index") !== undefined && $(this).data("index") !== null) {
          SetCameraSpotlight($(this).data("index"));
          if (!this.href.includes("#") && !this.href.includes('interdigitalatcmu.medium.com')) {
            gsap.to(".content", {css: {backgroundColor: "rgba(0,0,0,1)"}, duration: 0.5})
            setTimeout(() => {
              window.location = this.href
            }, 1000);
          }
          else {
            window.open(this.href, '_blank');
          }
        }
    })

    $('#process_dropdown').hover(function(e) {
      $('#nav_dropdown').css('display', 'block');
    }, function(e) {
      $('#nav_dropdown').css('display', 'none');
    })

    $('.home-menu-title').hover(function(e) {
      gsap.to($(this), {css: {color: '#6783E6'}, duration: 0.25});
    }, function(e) {
      if ($(this).hasClass('current-nav')) {
        gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
      }
      else {
        gsap.to($(this), {css: {color: '#f1f0e4'}, duration: 0.25});
      }
    })

    $('.navbar-link').hover(function(e) {
      gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
    }, function(e) {
      if ($(this).hasClass('current-nav')) {
        gsap.to($(this), {css: {color: '#34F5C5'}, duration: 0.25});
      }
      else {
        gsap.to($(this), {css: {color: '#f1f0e4'}, duration: 0.25});
      }
    })
  </script>
  <script type="text/javascript" src="js/gsap_anchor.js"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
</body>
</html>